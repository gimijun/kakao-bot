from flask import Flask, jsonify, request
import feedparser
import requests
from bs4 import BeautifulSoup
import re
import datetime
import json
import os

app = Flask(__name__)

def extract_image_from_entry(entry):
    if hasattr(entry, 'media_content'):
        for media in entry.media_content:
            if 'url' in media:
                return media['url']
    return "https://t1.daumcdn.net/media/img-section/news_card_default.png"

def fetch_rss_news(rss_url, max_count=5):
    feed = feedparser.parse(rss_url)
    news_items = []
    for entry in feed.entries[:max_count]:
        title = re.sub(r'<[^>]+>', '', entry.title)
        image = extract_image_from_entry(entry)
        link = entry.link
        news_items.append({
            "title": title,
            "image": image,
            "link": link
        })
    return news_items

def clean_image_url(image):
    if image.startswith("//"):
        return "https:" + image
    elif image.startswith("/"):
        return "https://www.donga.com" + image
    return image

def fetch_donga_search_news(keyword, max_count=5):
    url = f"https://www.donga.com/news/search?query={keyword}"
    headers = {
        "User-Agent": "Mozilla/5.0",
        "Accept-Language": "ko-KR,ko;q=0.9",
        "Referer": "https://www.donga.com/"
    }
    res = requests.get(url, headers=headers, timeout=10)
    if res.status_code != 200:
        return []

    soup = BeautifulSoup(res.text, "html.parser")
    articles = soup.select("ul.row_list li article")
    news_items = []

    for item in articles[:max_count]:
        title_tag = item.select_one("h4")
        link_tag = item.select_one("a")
        image_tag = item.select_one("header a div img")

        title = title_tag.get_text(strip=True) if title_tag else "ì œëª© ì—†ìŒ"
        link = "https:" + link_tag["href"] if link_tag and link_tag.has_attr("href") else "#"

        image = ""
        if image_tag:
            image = image_tag.get("src") or image_tag.get("data-src") or ""
            image = clean_image_url(image)

        news_items.append({
            "title": title,
            "image": image,
            "link": link
        })

    return news_items

def fetch_donga_trending_news(url, max_count=5):
    headers = {
        "User-Agent": "Mozilla/5.0"
    }
    res = requests.get(url, headers=headers, timeout=10)
    if res.status_code != 200:
        return []

    soup = BeautifulSoup(res.text, "html.parser")
    articles = soup.select("div.list ul li article")
    news_items = []

    for item in articles[:max_count]:
        title_tag = item.select_one("h4")
        link_tag = item.select_one("a")
        image_tag = item.select_one("header a img")

        title = title_tag.get_text(strip=True) if title_tag else "ì œëª© ì—†ìŒ"
        link = "https:" + link_tag["href"] if link_tag and link_tag.has_attr("href") else "#"

        image = ""
        if image_tag:
            image = image_tag.get("src") or image_tag.get("data-src") or ""
            image = clean_image_url(image)

        news_items.append({
            "title": title,
            "image": image,
            "link": link
        })

    return news_items

def list_card_response(title, rss_url, web_url):
    articles = fetch_rss_news(rss_url)
    if not articles:
        items = [{
            "title": f"{title} ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
            "imageUrl": "https://via.placeholder.com/200",
            "link": {"web": web_url}
        }]
    else:
        items = [{
            "title": a["title"],
            "imageUrl": a["image"],
            "link": {"web": a["link"]}
        } for a in articles]

    return jsonify({
        "version": "2.0",
        "template": {
            "outputs": [{
                "listCard": {
                    "header": {"title": f"{title} ë‰´ìŠ¤ TOP {len(items)}"},
                    "items": items,
                    "buttons": [{
                        "label": "ë”ë³´ê¸°",
                        "action": "webLink",
                        "webLinkUrl": web_url
                    }]
                }
            }]
        }
    })

def trending_card_response(title, web_url):
    articles = fetch_donga_trending_news(web_url)
    if not articles:
        items = [{
            "title": f"{title} ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
            "imageUrl": "https://via.placeholder.com/200",
            "link": {"web": web_url}
        }]
    else:
        items = [{
            "title": a["title"],
            "imageUrl": a["image"],
            "link": {"web": a["link"]}
        } for a in articles]

    return jsonify({
        "version": "2.0",
        "template": {
            "outputs": [{
                "listCard": {
                    "header": {"title": f"{title} TOP {len(items)}"},
                    "items": items,
                    "buttons": [{
                        "label": "ë”ë³´ê¸°",
                        "action": "webLink",
                        "webLinkUrl": web_url
                    }]
                }
            }]
        }
    })

def search_news_response(keyword, max_count=5):
    articles = fetch_donga_search_news(keyword, max_count=max_count)
    if not articles:
        items = [{
            "title": f"'{keyword}' ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
            "imageUrl": "https://via.placeholder.com/200",
            "link": {"web": f"https://www.donga.com/news/search?query={keyword}"}
        }]
    else:
        items = [{
            "title": a["title"],
            "imageUrl": a["image"],
            "link": {"web": a["link"]}
        } for a in articles]

    return jsonify({
        "version": "2.0",
        "template": {
            "outputs": [{
                "listCard": {
                    "header": {"title": f"'{keyword}' ê²€ìƒ‰ ê²°ê³¼"},
                    "items": items,
                    "buttons": [{
                        "label": "ë”ë³´ê¸°",
                        "action": "webLink",
                        "webLinkUrl": f"https://www.donga.com/news/search?query={keyword}"
                    }]
                }
            }]
        }
    })

@app.route("/news/ask_keyword", methods=["POST"])
def search_by_user_input():
    body = request.get_json()
    keyword = body.get("action", {}).get("params", {}).get("keyword", "").strip()

    if not keyword:
        keyword = body.get("userRequest", {}).get("utterance", "").strip()

    if not keyword:
        return jsonify({
            "version": "2.0",
            "template": {
                "outputs": [{
                    "simpleText": {"text": "ê²€ìƒ‰ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ ì£¼ì„¸ìš”."}
                }]
            }
        })

    return search_news_response(keyword, max_count=5)

@app.route("/news/politics", methods=["POST"])
def news_politics(): return list_card_response("ì •ì¹˜", "https://rss.donga.com/politics.xml", "https://www.donga.com/news/Politics")

@app.route("/news/economy", methods=["POST"])
def news_economy(): return list_card_response("ê²½ì œ", "https://rss.donga.com/economy.xml", "https://www.donga.com/news/Economy")

@app.route("/news/society", methods=["POST"])
def news_society(): return list_card_response("ì‚¬íšŒ", "https://rss.donga.com/national.xml", "https://www.donga.com/news/National")

@app.route("/news/world", methods=["POST"])
def news_world(): return list_card_response("êµ­ì œ", "https://rss.donga.com/international.xml", "https://www.donga.com/news/Inter")

@app.route("/news/science", methods=["POST"])
def news_science(): return list_card_response("IT/ê³¼í•™", "https://rss.donga.com/science.xml", "https://www.donga.com/news/It")

@app.route("/news/culture", methods=["POST"])
def news_culture(): return list_card_response("ë¬¸í™”ì—°ì˜ˆ", "https://rss.donga.com/culture.xml", "https://www.donga.com/news/Culture")

@app.route("/news/sports", methods=["POST"])
def news_sports(): return list_card_response("ìŠ¤í¬ì¸ ", "https://rss.donga.com/sports.xml", "https://www.donga.com/news/Sports")

@app.route("/news/entertainment", methods=["POST"])
def news_entertainment(): return list_card_response("ì—°ì˜ˆ", "https://rss.donga.com/entertainment.xml", "https://www.donga.com/news/Entertainment")

@app.route("/news/trending", methods=["POST"])
def trending_daily(): return trending_card_response("ìš”ì¦˜ ëœ¨ëŠ” ë‰´ìŠ¤", "https://www.donga.com/news/TrendNews/daily")

@app.route("/news/popular", methods=["POST"])
def trending_monthly(): return trending_card_response("ë§ì´ ë³¸ ë‰´ìŠ¤", "https://www.donga.com/news/TrendNews/monthly")

@app.route("/news/briefing", methods=["POST"])
def news_briefing():
    from flask import Flask, jsonify, request
import feedparser
import requests
from bs4 import BeautifulSoup
import re
import datetime
import json
import os

app = Flask(__name__)

# ... (ê¸°ì¡´ RSS ë‰´ìŠ¤ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ ìœ ì§€)

from flask import Flask, jsonify, request
import feedparser
import requests
from bs4 import BeautifulSoup
import re
import json
import pandas as pd
from datetime import datetime

app = Flask(__name__)

# JSON íŒŒì¼ë¡œë¶€í„° ì§€ì—­ â†’ ì¢Œí‘œ ì •ë³´ ë¡œë“œ
with open("/mnt/data/region_coords.json", encoding="utf-8") as f:
    region_coords = json.load(f)

def get_coords(region):
    return region_coords.get(region, (None, None))

@app.route("/weather/change-region", methods=["POST"])
def weather_by_region():
    body = request.get_json()
    region = body.get("action", {}).get("params", {}).get("sys_location", "ì„œìš¸")
    nx, ny = get_coords(region)
    if not nx or not ny:
        return jsonify({
            "version": "2.0",
            "template": {
                "outputs": [{
                    "simpleText": {"text": f"'{region}' ì§€ì—­ì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ ì£¼ì„¸ìš”."}
                }]
            }
        })

    try:
        now = datetime.now()
        base_date = now.strftime("%Y%m%d")
        base_time = now.strftime("%H00")
        service_key = "N/RBXLEXYr/O1xxA7qcJZY5LK63c1D44dWsoUszF+DHGpY+n2xAea7ruByvKh566Qf69vLarJBgGRXdVe4DlkA=="

        url = "http://apis.data.go.kr/1360000/VilageFcstInfoService_2.0/getUltraSrtNcst"
        params = {
            "serviceKey": service_key,
            "pageNo": "1",
            "numOfRows": "100",
            "dataType": "JSON",
            "base_date": base_date,
            "base_time": base_time,
            "nx": nx,
            "ny": ny
        }

        res = requests.get(url, params=params, timeout=5)
        data = res.json()
        items = data['response']['body']['items']['item']

        weather = {}
        for item in items:
            category = item['category']
            value = item['obsrValue']
            if category in ["T1H", "REH", "PM10", "PM25", "UV"]:
                weather[category] = value

        TMP = weather.get("T1H", "-")
        REH = weather.get("REH", "-")
        PM10 = weather.get("PM10", "-")
        PM25 = weather.get("PM25", "-")
        UV = weather.get("UV", "-")

    except Exception as e:
        return jsonify({
            "version": "2.0",
            "template": {
                "outputs": [{
                    "simpleText": {"text": f"ë‚ ì”¨ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}
                }]
            }
        })

    return jsonify({
        "version": "2.0",
        "template": {
            "outputs": [{
                "listCard": {
                    "header": {"title": f"â˜€ï¸ '{region}' í˜„ì¬ ë‚ ì”¨"},
                    "items": [
                        {"title": f"ê¸°ì˜¨ {TMP}â„ƒ", "description": ""},
                        {"title": f"ë¯¸ì„¸ë¨¼ì§€ {PM10}", "description": ""},
                        {"title": f"ì´ˆë¯¸ì„¸ë¨¼ì§€ {PM25}", "description": ""},
                        {"title": f"ìì™¸ì„  {UV}", "description": ""},
                        {"title": f"ìŠµë„ {REH}%", "description": ""}
                    ],
                    "buttons": [
                        {"label": "ë‹¤ë¥¸ ì§€ì—­ ë³´ê¸°", "action": "message", "messageText": "ì§€ì—­ ë³€ê²½í•˜ê¸°"},
                        {
                            "label": "ê¸°ìƒì²­ ì „êµ­ ë‚ ì”¨",
                            "action": "webLink",
                            "webLinkUrl": "https://www.weather.go.kr/w/weather/forecast/short-term.do"
                        }
                    ]
                }
            }]
        }
    })

@app.route("/briefing", methods=["POST"])
def combined_briefing():
    try:
        # ë‚ ì”¨ ì¹´ë“œ ìƒì„± (ì„œìš¸ ê³ ì •)
        region = "ì„œìš¸"
        nx, ny = get_coords(region)
        now = datetime.now()
        base_date = now.strftime("%Y%m%d")
        base_time = now.strftime("%H00")
        service_key = "N/RBXLEXYr/O1xxA7qcJZY5LK63c1D44dWsoUszF+DHGpY+n2xAea7ruByvKh566Qf69vLarJBgGRXdVe4DlkA=="
        url = "http://apis.data.go.kr/1360000/VilageFcstInfoService_2.0/getUltraSrtNcst"
        params = {
            "serviceKey": service_key,
            "pageNo": "1",
            "numOfRows": "100",
            "dataType": "JSON",
            "base_date": base_date,
            "base_time": base_time,
            "nx": nx,
            "ny": ny
        }
        res = requests.get(url, params=params, timeout=5)
        items = res.json()['response']['body']['items']['item']
        weather = {item['category']: item['obsrValue'] for item in items if item['category'] in ["T1H", "REH", "PM10", "PM25", "UV"]}
        TMP = weather.get("T1H", "-")
        REH = weather.get("REH", "-")
        PM10 = weather.get("PM10", "-")
        PM25 = weather.get("PM25", "-")
        UV = weather.get("UV", "-")
        weather_card = {
            "listCard": {
                "header": {"title": f"â˜€ï¸ '{region}' í˜„ì¬ ë‚ ì”¨"},
                "items": [
                    {"title": f"ê¸°ì˜¨ {TMP}â„ƒ", "description": ""},
                    {"title": f"ë¯¸ì„¸ë¨¼ì§€ {PM10}", "description": ""},
                    {"title": f"ì´ˆë¯¸ì„¸ë¨¼ì§€ {PM25}", "description": ""},
                    {"title": f"ìì™¸ì„  {UV}", "description": ""},
                    {"title": f"ìŠµë„ {REH}%", "description": ""}
                ],
                "buttons": [
                    {"label": "ì§€ì—­ ë³€ê²½í•˜ê¸°", "action": "message", "messageText": "ì§€ì—­ ë³€ê²½í•˜ê¸°"},
                    {"label": "ì „êµ­ë‚ ì”¨ ë³´ê¸°", "action": "webLink", "webLinkUrl": "https://www.weather.go.kr/w/weather/forecast/short-term.do"}
                ]
            }
        }

        # ë‰´ìŠ¤ í¬ë¡¤ë§ (ì‹¤ì‹œê°„ ë‰´ìŠ¤)
        news_url = "https://www.donga.com/news/List"
        soup = BeautifulSoup(requests.get(news_url, headers={"User-Agent": "Mozilla/5.0"}).text, "html.parser")
        articles = soup.select("#contents ul.row_list > li > article.news_card")
        news_items = []
        for item in articles[:5]:
            h_tag = item.select_one("div > h4 > a")
            img_tag = item.select_one("header > a > img")
            link = h_tag['href'] if h_tag and h_tag.has_attr('href') else "#"
            title = h_tag.get_text(strip=True) if h_tag else "ì œëª© ì—†ìŒ"
            image = img_tag['src'] if img_tag and img_tag.has_attr('src') else "https://via.placeholder.com/200"
            if image.startswith("/"):
                image = "https:" + image
            news_items.append({"title": title, "imageUrl": image, "link": {"web": link}})

        news_card = {
            "listCard": {
                "header": {"title": "ğŸ“° ì‹¤ì‹œê°„ ë‰´ìŠ¤ TOP 5"},
                "items": [
                    {"title": n["title"], "imageUrl": n["imageUrl"], "link": n["link"]} for n in news_items
                ],
                "buttons": [
                    {"label": "ì „ì²´ ë‰´ìŠ¤ ë³´ê¸°", "action": "webLink", "webLinkUrl": news_url}
                ]
            }
        }

        return jsonify({
            "version": "2.0",
            "template": {
                "outputs": [weather_card, news_card]
            }
        })

    except Exception as e:
        return jsonify({
            "version": "2.0",
            "template": {
                "outputs": [{"simpleText": {"text": f"ë¸Œë¦¬í•‘ ì˜¤ë¥˜: {str(e)}"}}]
            }
        })



@app.route("/", methods=["GET"])
def health():
    return "ì¹´ì¹´ì˜¤ ë‰´ìŠ¤ë´‡ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤."

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
